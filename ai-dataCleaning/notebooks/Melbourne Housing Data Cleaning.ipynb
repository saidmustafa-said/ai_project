{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23547, 21)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets import a dataset to perform the operations\n",
    "data = pd.read_csv('../data/raw/melbourne.csv')\n",
    "\n",
    "# lets check the shape of the dataset\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>03-09-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>03-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb          Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford    68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford     85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford  25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "\n",
       "         Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  03-09-2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  03-12-2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  04-02-2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the structure of the dataset\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Functions which will help us to identify the null values present in the dataframes\n",
    "\n",
    "#### The Functions which help us to know whether the data is null or not\n",
    "* ```isnull()```: Indicates the presence of Missing values in a dataset, return boolean values. i.e., It will return True if the data is missing and False if the data is not missing.\n",
    "* ```notnull()```: This Function is completely the Opposite of ```isnull()```, It also returns boolean values.\n",
    "\n",
    "#### The Functions which helps us to compute operations to check  whether all or some data is missing\n",
    "* ```any()```: It will be used where we want to include all the data for operations and Identification.\n",
    "* ```all()```: It will be used where we are only checking on some or any of the data for operations or Identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66918"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets first check if there is any null value present in the data\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "Pattern matched multiple keys",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_rows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1470\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32ms:\\Information Technology\\AI\\aiENV\\Lib\\site-packages\\pandas\\_config\\config.py:274\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m--> 274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32ms:\\Information Technology\\AI\\aiENV\\Lib\\site-packages\\pandas\\_config\\config.py:167\u001b[0m, in \u001b[0;36m_set_option\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_set_option() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwarg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(args[::\u001b[38;5;241m2\u001b[39m], args[\u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m]):\n\u001b[1;32m--> 167\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43m_get_single_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     o \u001b[38;5;241m=\u001b[39m _get_registered_option(key)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m o \u001b[38;5;129;01mand\u001b[39;00m o\u001b[38;5;241m.\u001b[39mvalidator:\n",
      "File \u001b[1;32ms:\\Information Technology\\AI\\aiENV\\Lib\\site-packages\\pandas\\_config\\config.py:134\u001b[0m, in \u001b[0;36m_get_single_key\u001b[1;34m(pat, silent)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such keys(s): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(pat)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keys) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OptionError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPattern matched multiple keys\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    135\u001b[0m key \u001b[38;5;241m=\u001b[39m keys[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m silent:\n",
      "\u001b[1;31mOptionError\u001b[0m: Pattern matched multiple keys"
     ]
    }
   ],
   "source": [
    "pd.set_option('max_rows', 1470)\n",
    "data.isnull().sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can see that, there are no missing values in the dataset**\n",
    "\n",
    "* Using ```isnull()``` function returns true, If there any data present in the cell and false if there is no data present in the cell.\n",
    "&nbsp;\n",
    "\n",
    "* Using ```isnull().sum()``` function would return the sum of null values present in each of the columns.\n",
    "&nbsp;\n",
    "\n",
    "* Using ```isnull().sum().sum()``` function would return the totak number of null values or missing values present in a dataset or dataframe.\n",
    "&nbsp;\n",
    "\n",
    "* In the Above Result we can see that every columns present in the dataset are having 0 null values, that means there is no null data in the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23547, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets try to take another dataframe, and try to handle missing values in the dataframe\n",
    "\n",
    "data = pd.read_csv('melbourne.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>68 Studley St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>Jellis</td>\n",
       "      <td>03-09-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8014</td>\n",
       "      <td>144.9958</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>03-12-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>18/659 Victoria St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VB</td>\n",
       "      <td>Rounds</td>\n",
       "      <td>04-02-2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8114</td>\n",
       "      <td>145.0116</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>04-03-2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Suburb             Address  Rooms Type      Price Method SellerG  \\\n",
       "0  Abbotsford       68 Studley St      2    h        NaN     SS  Jellis   \n",
       "1  Abbotsford        85 Turner St      2    h  1480000.0      S  Biggin   \n",
       "2  Abbotsford     25 Bloomburg St      2    h  1035000.0      S  Biggin   \n",
       "3  Abbotsford  18/659 Victoria St      3    u        NaN     VB  Rounds   \n",
       "4  Abbotsford        5 Charles St      3    h  1465000.0     SP  Biggin   \n",
       "\n",
       "         Date  Distance  Postcode  ...  Bathroom  Car  Landsize  BuildingArea  \\\n",
       "0  03-09-2016       2.5    3067.0  ...       1.0  1.0     126.0           NaN   \n",
       "1  03-12-2016       2.5    3067.0  ...       1.0  1.0     202.0           NaN   \n",
       "2  04-02-2016       2.5    3067.0  ...       1.0  0.0     156.0          79.0   \n",
       "3  04-02-2016       2.5    3067.0  ...       2.0  1.0       0.0           NaN   \n",
       "4  04-03-2017       2.5    3067.0  ...       2.0  0.0     134.0         150.0   \n",
       "\n",
       "   YearBuilt  CouncilArea Lattitude  Longtitude             Regionname  \\\n",
       "0        NaN        Yarra  -37.8014    144.9958  Northern Metropolitan   \n",
       "1        NaN        Yarra  -37.7996    144.9984  Northern Metropolitan   \n",
       "2     1900.0        Yarra  -37.8079    144.9934  Northern Metropolitan   \n",
       "3        NaN        Yarra  -37.8114    145.0116  Northern Metropolitan   \n",
       "4     1900.0        Yarra  -37.8093    144.9944  Northern Metropolitan   \n",
       "\n",
       "  Propertycount  \n",
       "0        4019.0  \n",
       "1        4019.0  \n",
       "2        4019.0  \n",
       "3        4019.0  \n",
       "4        4019.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23547 entries, 0 to 23546\n",
      "Data columns (total 21 columns):\n",
      "Suburb           23547 non-null object\n",
      "Address          23547 non-null object\n",
      "Rooms            23547 non-null int64\n",
      "Type             23547 non-null object\n",
      "Price            18396 non-null float64\n",
      "Method           23547 non-null object\n",
      "SellerG          23547 non-null object\n",
      "Date             23547 non-null object\n",
      "Distance         23546 non-null float64\n",
      "Postcode         23546 non-null float64\n",
      "Bedroom2         19066 non-null float64\n",
      "Bathroom         19063 non-null float64\n",
      "Car              18921 non-null float64\n",
      "Landsize         17410 non-null float64\n",
      "BuildingArea     10018 non-null float64\n",
      "YearBuilt        11540 non-null float64\n",
      "CouncilArea      15656 non-null object\n",
      "Lattitude        19243 non-null float64\n",
      "Longtitude       19243 non-null float64\n",
      "Regionname       23546 non-null object\n",
      "Propertycount    23546 non-null float64\n",
      "dtypes: float64(12), int64(1), object(8)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# lets check the basic information about the data\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23547, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check whether this dataset is having any null values or not\n",
    "\n",
    "# first lets check how many rows are having all the null values\n",
    "data.isnull().all(axis = 1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The returned value is the total number of missing values in the dataframe\n",
    "* 66, 918 number of data points are missing that is huge.\n",
    "* let's also check the details of the missing values.\n",
    "* In the detailed report we will be able to check how many missing values are associated with each of teh columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb               0\n",
       "Address              0\n",
       "Rooms                0\n",
       "Type                 0\n",
       "Price             5151\n",
       "Method               0\n",
       "SellerG              0\n",
       "Date                 0\n",
       "Distance             1\n",
       "Postcode             1\n",
       "Bedroom2          4481\n",
       "Bathroom          4484\n",
       "Car               4626\n",
       "Landsize          6137\n",
       "BuildingArea     13529\n",
       "YearBuilt        12007\n",
       "CouncilArea       7891\n",
       "Lattitude         4304\n",
       "Longtitude        4304\n",
       "Regionname           1\n",
       "Propertycount        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the number of missing values in the dataset\n",
    "# we are check the missing values in the context of columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that there are many columns which are having null values, Infact there are some columns where we have huge number of missing values.\n",
    "* lets also check the percentage of missing values present in the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Handle Missing Values from a Dataframe\n",
    "\n",
    "* **We have already discussed the ways to handle the missing values from the Dataset, but when talking about it in broad sense then only two major choices:**\n",
    "    * To ```drop/delete``` the missing values\n",
    "    * To ```impute``` the missinng values\n",
    "    \n",
    "* **We have to take decision regarding which of the two options to go with depending on the missing values**.\n",
    "    * We can drop/delete the missinng values only when the missing percentage is more than 50% or it is not so important.\n",
    "    * in that case, we have to impute the values using any of the methods listed in the introduction part.\n",
    "    \n",
    "lets take some examples using the available dataset to check how to impute or delelete the missing values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods we will use to Impute Missing Values\n",
    "\n",
    "* There are many ways to Impute Missing Values, some of them which are popularly used:\n",
    "    * ```dropna()```: This Function is used to drops the missing values from a dataset and returns the rest of the dataframe.\n",
    "    * ```fillna()```: This Function is used to replace the missing value with a specified value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suburb            0.00\n",
      "Address           0.00\n",
      "Rooms             0.00\n",
      "Type              0.00\n",
      "Price            21.88\n",
      "Method            0.00\n",
      "SellerG           0.00\n",
      "Date              0.00\n",
      "Distance          0.00\n",
      "Postcode          0.00\n",
      "Bedroom2         19.03\n",
      "Bathroom         19.04\n",
      "Car              19.65\n",
      "Landsize         26.06\n",
      "BuildingArea     57.46\n",
      "YearBuilt        50.99\n",
      "CouncilArea      33.51\n",
      "Lattitude        18.28\n",
      "Longtitude       18.28\n",
      "Regionname        0.00\n",
      "Propertycount     0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# lets check the percentage of missing values in the columns of the dataset\n",
    "\n",
    "percentage_of_missing_values = round(100*(data.isnull().sum()/len(data.index)), 2)\n",
    "print(percentage_of_missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: green;\">It can be noticed very easily from the above results that there are many columns have huge percentage of data missing from the dataset. There are columns which are having ```18% to 26%``` of values missing from the data, and also there are some columns which are having ```33% to 56%``` of values missing from the data.\n",
    "\n",
    "* What action should we take, should we remove them all, or impute.\n",
    "    * We ```cannot remove the columns having 18% to 26% missing values```, so In this case we will have to impute the missing values using one of the methods.\n",
    "        * It is very important to impute the missing values for these columns as If we remove these columns from the data having only 18 to 26% of the missing values then we will face huge data loss, In that case, We might lose some of the very important and relevant data for the analysis and results.\n",
    "    \n",
    "    * But, ```We can remove the columns having 33 to 56% of missing values```, so In this case will have to drop these columns from the data.\n",
    "        * It is very important to remove these columns because if we impute these missing values then we can introduce a huge bias into the data, which will be bad for the analysis of the data, It might also return inappropriate and misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the Columns using drop() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Suburb', 'Address', 'Rooms', 'Type', 'Price', 'Method', 'SellerG',\n",
       "       'Date', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
       "       'Landsize', 'Lattitude', 'Longtitude', 'Regionname', 'Propertycount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing the three columns having 33% to 56% of missing values in the dataset\n",
    "data = data.drop('BuildingArea', axis=1)\n",
    "data = data.drop('YearBuilt', axis=1)\n",
    "data = data.drop('CouncilArea', axis=1)\n",
    "\n",
    "# data = data.drop(['Building Area', 'YearBuilt', 'CouncilArea'], axis = 1)\n",
    "\n",
    "# lets check the columns left after the deletion of above listed columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4278"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of rows having > 5 missing values\n",
    "# use len(df.index)\n",
    "len(data[data.isnull().sum(axis=1) > 5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retaining the rows having <= 5 NaNs\n",
    "data = data[data.isnull().sum(axis=1) <= 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb            0.00\n",
       "Address           0.00\n",
       "Rooms             0.00\n",
       "Type              0.00\n",
       "Price            21.71\n",
       "Method            0.00\n",
       "SellerG           0.00\n",
       "Date              0.00\n",
       "Distance          0.00\n",
       "Postcode          0.00\n",
       "Bedroom2          1.05\n",
       "Bathroom          1.07\n",
       "Car               1.81\n",
       "Landsize          9.65\n",
       "Lattitude         0.13\n",
       "Longtitude        0.13\n",
       "Regionname        0.00\n",
       "Propertycount     0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It can be seen that ```Price Column``` still has large number of missing values i.e., 21% of the data is missing. If we impute these values it will introduce heavy bias into the data and the results will be misleading so It is better to discard the rows where Price is having missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all the rows where there is a missing value in the Price Column\n",
    "data = data[~np.isnan(data['Price'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         1.05\n",
       "Bathroom         1.07\n",
       "Car              1.76\n",
       "Landsize         9.83\n",
       "Lattitude        0.15\n",
       "Longtitude       0.15\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, we have Landsize, which is having high percentage of missing values, lets check the range of values present in the Landsize attribute of the data, so that we can impute the missing values present in the Landsize Attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     13603.000000\n",
       "mean        558.116371\n",
       "std        3987.326586\n",
       "min           0.000000\n",
       "25%         176.500000\n",
       "50%         440.000000\n",
       "75%         651.000000\n",
       "max      433014.000000\n",
       "Name: Landsize, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the description of values in the Landsize Column\n",
    "data['Landsize'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above description of the range of values present in the landsize columns supported by mean, standard deviatio, minimum, maximum, 25% percentile, 50% percentile, 75% percentile etc.\n",
    "\n",
    "* We can see that the Minimum value is 0 and Maximum value is 433014, there is huge difference so both mean and median function would not work\n",
    "\n",
    "* Also, there is a huge difference in the 25th, 50th, and 75th percentiles indicating that if we impute the values for Landsize column we will most probably introduce bias into the data.\n",
    "\n",
    "* It is most appropriate to remove the rows where we find null values for Landsize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Suburb           0.00\n",
       "Address          0.00\n",
       "Rooms            0.00\n",
       "Type             0.00\n",
       "Price            0.00\n",
       "Method           0.00\n",
       "SellerG          0.00\n",
       "Date             0.00\n",
       "Distance         0.00\n",
       "Postcode         0.00\n",
       "Bedroom2         0.00\n",
       "Bathroom         0.01\n",
       "Car              0.46\n",
       "Landsize         0.00\n",
       "Lattitude        0.16\n",
       "Longtitude       0.16\n",
       "Regionname       0.00\n",
       "Propertycount    0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing  all the rows where there is a null value in the landsize column\n",
    "data = data[~np.isnan(data['Landsize'])]\n",
    "\n",
    "# lets check the summary again\n",
    "round(100*(data.isnull().sum()/len(data.index)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can see that now we have very low fraction of missing values in the columns Bathroom, Car, Lattitude, and Longitude\n",
    "* Lets check the range values of Lattitude and Longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13581.000000</td>\n",
       "      <td>13581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-37.809204</td>\n",
       "      <td>144.995221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.079257</td>\n",
       "      <td>0.103913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-38.182550</td>\n",
       "      <td>144.431810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-37.856820</td>\n",
       "      <td>144.929600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-37.802360</td>\n",
       "      <td>145.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-37.756400</td>\n",
       "      <td>145.058320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-37.408530</td>\n",
       "      <td>145.526350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lattitude    Longtitude\n",
       "count  13581.000000  13581.000000\n",
       "mean     -37.809204    144.995221\n",
       "std        0.079257      0.103913\n",
       "min      -38.182550    144.431810\n",
       "25%      -37.856820    144.929600\n",
       "50%      -37.802360    145.000100\n",
       "75%      -37.756400    145.058320\n",
       "max      -37.408530    145.526350"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# describing the values for lattitude and longitude\n",
    "data[['Lattitude','Longtitude']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing using fillna() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as there is minute difference between the values of min, mean, max, 25th, 50th, and 75th percentile. \n",
    "# so we can use mean function to impute the values in lattitude and longtitude.\n",
    "\n",
    "data['Lattitude'] = data['Lattitude'].fillna(data['Lattitude'].mean())\n",
    "data['Longtitude'].fillna(data['Longtitude'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    7517\n",
       "2.0    4987\n",
       "3.0     921\n",
       "4.0     106\n",
       "0.0      34\n",
       "5.0      28\n",
       "6.0       5\n",
       "8.0       2\n",
       "7.0       2\n",
       "Name: Bathroom, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the values present in the Bathroom Column\n",
    "\n",
    "data['Bathroom'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0     5606\n",
       "1.0     5515\n",
       "0.0     1026\n",
       "3.0      748\n",
       "4.0      507\n",
       "5.0       63\n",
       "6.0       54\n",
       "8.0        9\n",
       "7.0        8\n",
       "10.0       3\n",
       "9.0        1\n",
       "Name: Car, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets also check the values present in the Car Column\n",
    "\n",
    "data['Car'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to impute the values in Categorical Columns using the Mode function\n",
    "\n",
    "data['Bathroom'].fillna(data['Bathroom'].mode()[0], inplace = True)\n",
    "data['Car'].fillna(data['Car'].mode()[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets check the missing values present in the data\n",
    "\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that there no null values left in the dataset i.e., we are done with this tutorial on Handling Missing Values present in Data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
